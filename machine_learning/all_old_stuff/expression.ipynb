{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting soluble expression \n",
    "\n",
    "features = [\n",
    "    u'total_score', u'fa_rep', u'hbond_sc', u'tot_pstat_pm', u'tot_nlpstat_pm', u'tot_burunsat_pm',\n",
    "    u'tot_hbond_pm', u'tot_NLconts_pm', u'tot_nlsurfaceE_pm',\n",
    "    u'SR_1_total_score', u'SR_1_fa_rep', u'SR_1_hbond_sc', u'SR_1_hbond_pm',\n",
    "    u'SR_1_burunsat_pm', u'SR_1_pstat_pm', u'SR_1_nlpstat_pm', \n",
    "    u'SR_2_total_score', u'SR_2_fa_rep', u'SR_2_hbond_sc', u'SR_2_hbond_pm', \n",
    "    u'SR_2_burunsat_pm', u'SR_2_pstat_pm', u'SR_2_nlpstat_pm', \n",
    "    u'SR_3_total_score', u'SR_3_fa_rep', u'SR_3_hbond_sc', u'SR_3_hbond_pm',\n",
    "    u'SR_3_burunsat_pm', u'SR_3_pstat_pm', u'SR_3_nlpstat_pm',\n",
    "    u'SR_4_total_score', u'SR_4_fa_rep', u'SR_4_hbond_sc', u'SR_4_hbond_pm', \n",
    "    u'SR_4_burunsat_pm', u'SR_4_pstat_pm', u'SR_4_nlpstat_pm', \n",
    "    u'SR_5_total_score', u'SR_5_fa_rep', u'SR_5_hbond_sc', u'SR_5_interf_E_1_2',\n",
    "    u'SR_5_dsasa_1_2', u'SR_5_hbond_pm', u'SR_5_burunsat_pm'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404 positive class labels\n",
      "152 negative class labels\n"
     ]
    }
   ],
   "source": [
    "# get the expression data \n",
    "\n",
    "import pandas\n",
    "\n",
    "df = pandas.read_csv( '../data_sets/experimental/expr_144_mutants.csv', index_col=0 ) \n",
    "#df.expression = df.expression.astype( bool ).astype( int ) \n",
    "\n",
    "# get the features (enzyme design) \n",
    "\n",
    "f = pandas.read_csv( '../data_sets/rosetta/enzyme_design_noncovalent.csv', sep='\\s+' )\n",
    "f.description = f.description.str.split( '_' ).str[1]\n",
    "f = f.groupby( 'description' ).apply( lambda x: x.sort_values( by='SR_3_total_score' ).head(4) )\n",
    "f.index = f.description\n",
    "\n",
    "df = df.join( f ).dropna()\n",
    "\n",
    "df.shape\n",
    "\n",
    "print len( df.expression[ df.expression > 0 ] ), 'positive class labels' \n",
    "print len( df.expression[ df.expression < 1 ] ), 'negative class labels' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tot_total_neg_charges</th>\n",
       "      <td>-0.173465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_5_hbond_sc</th>\n",
       "      <td>-0.171772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_5_interf_E_1_2</th>\n",
       "      <td>-0.125714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_5_total_score</th>\n",
       "      <td>-0.125519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_5_burunsat_pm</th>\n",
       "      <td>-0.092141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_3_hbond_pm</th>\n",
       "      <td>-0.076566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_1_hbond_pm</th>\n",
       "      <td>-0.076566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_3_all_cst</th>\n",
       "      <td>-0.071878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_1_all_cst</th>\n",
       "      <td>-0.071878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_4_hbond_pm</th>\n",
       "      <td>-0.066317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_total_pos_charges</th>\n",
       "      <td>-0.058961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_cst</th>\n",
       "      <td>-0.047462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_2_hbond_sc</th>\n",
       "      <td>-0.046399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_5_all_cst</th>\n",
       "      <td>-0.041780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_1_burunsat_pm</th>\n",
       "      <td>-0.040845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_3_burunsat_pm</th>\n",
       "      <td>-0.040845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_2_fa_rep</th>\n",
       "      <td>-0.036407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_2_burunsat_pm</th>\n",
       "      <td>-0.033624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_5_fa_rep</th>\n",
       "      <td>-0.030979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hbond_sc</th>\n",
       "      <td>-0.030887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_1_nlpstat_pm</th>\n",
       "      <td>-0.028939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_3_nlpstat_pm</th>\n",
       "      <td>-0.028939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_2_total_score</th>\n",
       "      <td>-0.028783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_4_nlpstat_pm</th>\n",
       "      <td>-0.014215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_burunsat_pm</th>\n",
       "      <td>-0.005311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_2_all_cst</th>\n",
       "      <td>0.002574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_score</th>\n",
       "      <td>0.015863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fa_rep</th>\n",
       "      <td>0.016517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_1_fa_rep</th>\n",
       "      <td>0.019630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_3_fa_rep</th>\n",
       "      <td>0.019630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_1_pstat_pm</th>\n",
       "      <td>0.023152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_3_pstat_pm</th>\n",
       "      <td>0.023152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_2_hbond_pm</th>\n",
       "      <td>0.043961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_nlsurfaceE_pm</th>\n",
       "      <td>0.046488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_5_dsasa_1_2</th>\n",
       "      <td>0.054628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_4_pstat_pm</th>\n",
       "      <td>0.056838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_hbond_pm</th>\n",
       "      <td>0.065465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_2_pstat_pm</th>\n",
       "      <td>0.068368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_4_hbond_sc</th>\n",
       "      <td>0.071616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_nlpstat_pm</th>\n",
       "      <td>0.073917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_4_fa_rep</th>\n",
       "      <td>0.080678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_2_nlpstat_pm</th>\n",
       "      <td>0.084570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_total_charge</th>\n",
       "      <td>0.099582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_4_burunsat_pm</th>\n",
       "      <td>0.105264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_4_total_score</th>\n",
       "      <td>0.110722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_NLconts_pm</th>\n",
       "      <td>0.123357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_5_hbond_pm</th>\n",
       "      <td>0.129234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_3_total_score</th>\n",
       "      <td>0.130499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_1_total_score</th>\n",
       "      <td>0.130499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_pstat_pm</th>\n",
       "      <td>0.131770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_1_hbond_sc</th>\n",
       "      <td>0.152640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_3_hbond_sc</th>\n",
       "      <td>0.152640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expression</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_seq_recovery</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_4_all_cst</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_5</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       expression\n",
       "tot_total_neg_charges   -0.173465\n",
       "SR_5_hbond_sc           -0.171772\n",
       "SR_5_interf_E_1_2       -0.125714\n",
       "SR_5_total_score        -0.125519\n",
       "SR_5_burunsat_pm        -0.092141\n",
       "SR_3_hbond_pm           -0.076566\n",
       "SR_1_hbond_pm           -0.076566\n",
       "SR_3_all_cst            -0.071878\n",
       "SR_1_all_cst            -0.071878\n",
       "SR_4_hbond_pm           -0.066317\n",
       "tot_total_pos_charges   -0.058961\n",
       "all_cst                 -0.047462\n",
       "SR_2_hbond_sc           -0.046399\n",
       "SR_5_all_cst            -0.041780\n",
       "SR_1_burunsat_pm        -0.040845\n",
       "SR_3_burunsat_pm        -0.040845\n",
       "SR_2_fa_rep             -0.036407\n",
       "SR_2_burunsat_pm        -0.033624\n",
       "SR_5_fa_rep             -0.030979\n",
       "hbond_sc                -0.030887\n",
       "SR_1_nlpstat_pm         -0.028939\n",
       "SR_3_nlpstat_pm         -0.028939\n",
       "SR_2_total_score        -0.028783\n",
       "SR_4_nlpstat_pm         -0.014215\n",
       "tot_burunsat_pm         -0.005311\n",
       "SR_2_all_cst             0.002574\n",
       "total_score              0.015863\n",
       "fa_rep                   0.016517\n",
       "SR_1_fa_rep              0.019630\n",
       "SR_3_fa_rep              0.019630\n",
       "SR_1_pstat_pm            0.023152\n",
       "SR_3_pstat_pm            0.023152\n",
       "SR_2_hbond_pm            0.043961\n",
       "tot_nlsurfaceE_pm        0.046488\n",
       "SR_5_dsasa_1_2           0.054628\n",
       "SR_4_pstat_pm            0.056838\n",
       "tot_hbond_pm             0.065465\n",
       "SR_2_pstat_pm            0.068368\n",
       "SR_4_hbond_sc            0.071616\n",
       "tot_nlpstat_pm           0.073917\n",
       "SR_4_fa_rep              0.080678\n",
       "SR_2_nlpstat_pm          0.084570\n",
       "tot_total_charge         0.099582\n",
       "SR_4_burunsat_pm         0.105264\n",
       "SR_4_total_score         0.110722\n",
       "tot_NLconts_pm           0.123357\n",
       "SR_5_hbond_pm            0.129234\n",
       "SR_3_total_score         0.130499\n",
       "SR_1_total_score         0.130499\n",
       "tot_pstat_pm             0.131770\n",
       "SR_1_hbond_sc            0.152640\n",
       "SR_3_hbond_sc            0.152640\n",
       "expression               1.000000\n",
       "tot_seq_recovery              NaN\n",
       "SR_1                          NaN\n",
       "SR_2                          NaN\n",
       "SR_3                          NaN\n",
       "SR_4                          NaN\n",
       "SR_4_all_cst                  NaN\n",
       "SR_5                          NaN"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()[ [ 'expression' ] ].sort_values( 'expression' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.726618705036\n"
     ]
    }
   ],
   "source": [
    "# we will use 40ish features and 131 protein models (each is average of lowest 10 by total_score) \n",
    "# to train an SVM classifier \n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "X = df[ features ] \n",
    "X = scaler.fit_transform( X ) \n",
    "y = df[ 'expression' ] \n",
    "\n",
    "X.shape, y.shape\n",
    "\n",
    "print y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.40      0.26      0.32       152\n",
      "          1       0.75      0.85      0.80       404\n",
      "\n",
      "avg / total       0.66      0.69      0.67       556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pln = Pipeline([ ( 'pca', PCA(whiten=True) ), ( 'svm', SVC( class_weight='balanced' ) ), ])\n",
    "param_grid = dict( svm__C=[0.3,3,30], svm__gamma=[1e-4,1e-3,1e-2], pca__n_components=[2,5,10,20] ) \n",
    "grid = GridSearchCV( pln, param_grid, cv=3 ) \n",
    "grid.fit( X, y ) \n",
    "y_pred = grid.predict( X ) \n",
    "print classification_report( y, y_pred ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pca__n_components': 2, 'svm__C': 30, 'svm__gamma': 0.0001}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.19      0.26       152\n",
      "          1       0.75      0.91      0.82       404\n",
      "\n",
      "avg / total       0.66      0.71      0.67       556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pln = Pipeline([ ( 'pca', PCA() ), ( 'svm', SVC( class_weight='balanced' ) ), ])\n",
    "param_grid = dict( svm__C=[0.3,3,30], svm__gamma=[1e-4,1e-3,1e-2], pca__n_components=[2,5,10,20] ) \n",
    "grid = GridSearchCV( pln, param_grid, cv=3 ) \n",
    "grid.fit( X, y ) \n",
    "y_pred = grid.predict( X ) \n",
    "print grid.best_params_\n",
    "print classification_report( y, y_pred ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.60      0.54       114\n",
      "          1       0.83      0.77      0.80       303\n",
      "\n",
      "avg / total       0.74      0.72      0.73       417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pln = Pipeline([ ( 'pca', PCA() ), ( 'svm', SVC( class_weight='balanced' ) ), ])\n",
    "param_grid = dict( svm__C=[0.3,3,30], svm__gamma=[1e-4,1e-3,1e-2], pca__n_components=[2,5,10,20] ) \n",
    "grid = GridSearchCV( pln, param_grid, cv=3 ) \n",
    "grid.fit( X, y ) \n",
    "y_pred = grid.predict( X ) \n",
    "print classification_report( y, y_pred ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features : 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEcCAYAAADQqlM0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncM45lxfPOJxzzuXl/wEwlxlH18GFAwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118088a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# # Build a classification task using 3 informative features\n",
    "# X, y = make_classification(n_samples=1000, n_features=25, n_informative=3,\n",
    "#                            n_redundant=2, n_repeated=0, n_classes=8,\n",
    "#                            n_clusters_per_class=1, random_state=0)\n",
    "\n",
    "# Create the RFE object and compute a cross-validated score.\n",
    "pca = PCA( n_components=2, whiten=True ) \n",
    "X = pca.fit_transform( X ) \n",
    "svc = SVC(kernel=\"linear\", class_weight='balanced' )\n",
    "# The \"accuracy\" scoring is proportional to the number of correct\n",
    "# classifications\n",
    "rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(y, 2),\n",
    "              scoring='accuracy')\n",
    "rfecv.fit(X, y)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# streamlined version \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score\n",
    "\n",
    "cv = StratifiedKFold( y, n_folds=10, shuffle=True )\n",
    "classifier = svm.SVC( kernel='linear', C=30 )\n",
    "cross_val = cross_val_score( classifier, X, y, cv=cv) \n",
    "\n",
    "print 'mean accuracy:', cross_val.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a plot of cross validation performance with auc for each fold \n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold( y, n_folds=10, shuffle=True )\n",
    "classifier = svm.SVC( kernel='rbf', probability=True, random_state=1 )\n",
    "\n",
    "mean_tpr = 0.0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "all_tpr = []\n",
    "\n",
    "plt.figure( figsize=(10,10) )\n",
    "\n",
    "for i, (train, test) in enumerate(cv):\n",
    "    print i, \n",
    "    probas_ = classifier.fit(X[train], y[train]).predict_proba(X[test])\n",
    "    fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "    mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "    mean_tpr[0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n",
    "    print 'done,',  \n",
    "\n",
    "plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')\n",
    "\n",
    "mean_tpr /= len(cv)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, 'k--', label='Mean ROC (area = %0.2f)' % mean_auc, lw=2)\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
